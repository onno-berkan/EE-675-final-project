{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = \"/Users/apple/Documents/MATLAB/EE 675/Willett Data/tuning-tasks-all/\"\n",
    "import scipy.io\n",
    "\n",
    "fiftyWordDat = scipy.io.loadmat(baseDir+'tuningTasks/t12.2022.05.03_fiftyWordSet.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fiftyWordDat['feat'] = np.concatenate([fiftyWordDat['tx2'][:,:32].astype(np.float32), fiftyWordDat['tx2'][:,96:128].astype(np.float32), fiftyWordDat['spikePow'][:,:32].astype(np.float32), fiftyWordDat['spikePow'][:,96:128].astype(np.float32)], axis=1)\n",
    "fiftyWordDat['feat'] = np.sqrt(fiftyWordDat['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the bins for yes and no trials\n",
    "\n",
    "yesIdx = np.where(fiftyWordDat['cueList'] == 'yes')[1][0]\n",
    "noIdx = np.where(fiftyWordDat['cueList'] == 'no')[1][0]\n",
    "\n",
    "noTrials = np.where(fiftyWordDat['trialCues'] == noIdx)[0]\n",
    "yesTrials = np.where(fiftyWordDat['trialCues'] == yesIdx)[0]\n",
    "\n",
    "noTrialEpochs = [fiftyWordDat['goTrialEpochs'][trialNum] for trialNum in noTrials]\n",
    "yesTrialEpochs = [fiftyWordDat['goTrialEpochs'][trialNum] for trialNum in yesTrials]\n",
    "\n",
    "noTrialBins = [fiftyWordDat['feat'][epoch[1] - 50:epoch[1]] for epoch in noTrialEpochs] # the last 50 bins were found to be the most informative\n",
    "yesTrialBins = [fiftyWordDat['feat'][epoch[1] - 50:epoch[1]] for epoch in yesTrialEpochs] # (20, 50, 256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "\n",
    "nTrain = 16\n",
    "\n",
    "noTrain, noTest = noTrialBins[:nTrain], noTrialBins[nTrain:]\n",
    "yesTrain, yesTest = yesTrialBins[:nTrain], yesTrialBins[nTrain:]\n",
    "\n",
    "# stack the arrays\n",
    "yesTrain, noTrain = np.concatenate(yesTrain, axis=0), np.concatenate(noTrain, axis=0) # (16*50, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply factor analysis (FA) -- this is to initialize the C and R matrices of the Kalman filter for EM\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "def get_initial_params(data_stacked, n_states):\n",
    "    print(\"Running Factor Analysis for initialization\")\n",
    "    fa = FactorAnalysis(n_components=n_states, random_state=42)\n",
    "    fa.fit(data_stacked)\n",
    "    \n",
    "    # Extract matrices\n",
    "    # Sklearn components are (n_states, n_features), we need (n_features, n_states)\n",
    "    C_init = fa.components_.T \n",
    "    \n",
    "    # FA gives independent noise variance for each electrode\n",
    "    R_init = np.diag(fa.noise_variance_)\n",
    "    \n",
    "    return C_init, R_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kalman filter function, tunes using EM\n",
    "\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "def train_kalman_model(data_stacked, n_states, n_em_iters=10):\n",
    "    # factor analysis\n",
    "    C_init, R_init = get_initial_params(data_stacked, n_states)\n",
    "    \n",
    "    # Setup the Kalman Filter\n",
    "    # We initialize A (transition) as Identity + small noise (Random walk assumption to start)\n",
    "    # We fix observation matrices to the FA result initially, but let EM refine them\n",
    "    kf = KalmanFilter(\n",
    "        n_dim_state=n_states,\n",
    "        n_dim_obs=128,\n",
    "        transition_matrices=np.eye(n_states), \n",
    "        observation_matrices=C_init,\n",
    "        observation_covariance=R_init,\n",
    "        em_vars=['transition_matrices', 'observation_matrices', \n",
    "                 'transition_covariance', 'observation_covariance', \n",
    "                 'initial_state_mean', 'initial_state_covariance']\n",
    "    )\n",
    "    \n",
    "    # 3. Run EM\n",
    "    print(f\"Running EM for {n_em_iters} iterations...\")\n",
    "    kf = kf.em(data_stacked, n_iter=n_em_iters)\n",
    "    \n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes model\n",
      "Running Factor Analysis for initialization\n",
      "Running EM for 10 iterations...\n"
     ]
    }
   ],
   "source": [
    "stateDim = 12\n",
    "\n",
    "print(\"yes model\")\n",
    "model_yes = train_kalman_model(yesTrain, stateDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no model\n",
      "Running Factor Analysis for initialization\n",
      "Running EM for 10 iterations...\n"
     ]
    }
   ],
   "source": [
    "print(\"no model\")\n",
    "model_no = train_kalman_model(noTrain, stateDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log-likelihoods per KF per word\n",
    "def calc_log_likelihood(kf_model, trial_data):\n",
    "    # pykalman has a .score() method that computes log-likelihood!\n",
    "    # It expects (n_timesteps, n_features)\n",
    "    return kf_model.loglikelihood(trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(test_trials, true_label, model_yes, model_no):\n",
    "    correct = 0\n",
    "    total = len(test_trials)\n",
    "    \n",
    "    print(f\"\\nEvaluating True Label: '{true_label}'\")\n",
    "    for i, trial in enumerate(test_trials):\n",
    "        # Score against Yes Model\n",
    "        ll_yes = calc_log_likelihood(model_yes, trial)\n",
    "        \n",
    "        # Score against No Model\n",
    "        ll_no = calc_log_likelihood(model_no, trial)\n",
    "        \n",
    "        # Decision\n",
    "        prediction = \"Yes\" if ll_yes > ll_no else \"No\"\n",
    "        \n",
    "        is_correct = (prediction == true_label)\n",
    "        if is_correct: correct += 1\n",
    "        \n",
    "        print(f\"  Trial {i+1}: LL(Yes)={ll_yes:.1f}, LL(No)={ll_no:.1f} -> Pred: {prediction} [{'Correct' if is_correct else 'WRONG'}]\")\n",
    "        \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating True Label: 'Yes'\n",
      "  Trial 1: LL(Yes)=-14918.6, LL(No)=-14824.9 -> Pred: No [WRONG]\n",
      "  Trial 2: LL(Yes)=-14103.6, LL(No)=-14287.4 -> Pred: Yes [Correct]\n",
      "  Trial 3: LL(Yes)=-14043.9, LL(No)=-13862.7 -> Pred: No [WRONG]\n",
      "  Trial 4: LL(Yes)=-12905.4, LL(No)=-13031.1 -> Pred: Yes [Correct]\n",
      "\n",
      "Evaluating True Label: 'No'\n",
      "  Trial 1: LL(Yes)=-12883.7, LL(No)=-12697.1 -> Pred: No [Correct]\n",
      "  Trial 2: LL(Yes)=-13774.2, LL(No)=-13442.3 -> Pred: No [Correct]\n",
      "  Trial 3: LL(Yes)=-13270.0, LL(No)=-12935.0 -> Pred: No [Correct]\n",
      "  Trial 4: LL(Yes)=-13912.8, LL(No)=-13644.4 -> Pred: No [Correct]\n",
      "\n",
      "Chance Level: 50%\n",
      "\n",
      "Average Accuracy: 75.0%\n"
     ]
    }
   ],
   "source": [
    "# Run Evaluation\n",
    "acc_yes = evaluate_accuracy(yesTest, \"Yes\", model_yes, model_no)\n",
    "acc_no = evaluate_accuracy(noTest, \"No\", model_yes, model_no)\n",
    "\n",
    "print(f\"\\nChance Level: 50%\")\n",
    "print(f\"\\nAverage Accuracy: {(acc_yes + acc_no)/2 * 100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "675-final-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
